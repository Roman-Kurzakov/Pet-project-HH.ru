{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.5845.660 YaBrowser/23.9.0.0 Safari/537.36',\n",
    "    'Host': 'chelyabinsk.hh.ru',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "    'Accept-Language': 'ru,en-US;q=0.7,en;q=0.3',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'DNT': '1',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "sess = requests.Session()\n",
    "sess.headers.update(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = uc.Chrome(headless=True,use_subprocess=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(start_html, num_of_vacancy):\n",
    "\n",
    "    start_urls = list(set(re.findall('http[s]?://chelyabinsk.hh.ru/vacancy/[0-9]+', start_html)))\n",
    "    \n",
    "    while len(start_urls) < num_of_vacancy:\n",
    "    \n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        button_next = driver.find_element(By.LINK_TEXT, 'дальше')\n",
    "        button_next.click()\n",
    "        time.sleep(3)\n",
    "        html = driver.page_source\n",
    "        current_urls = re.findall('http[s]?://chelyabinsk.hh.ru/vacancy/[0-9]+', html)\n",
    "        for url in current_urls:\n",
    "            start_urls.append(url)\n",
    "        print('Get unique URLS: ', len(set(current_urls)))\n",
    "        \n",
    "    all_urls = list(set(start_urls))\n",
    "\n",
    "    return all_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_codes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаю коды локаций в которых больше 2к резюме\n",
    "\n",
    "for i in range(1,113):\n",
    "    url = f\"https://chelyabinsk.hh.ru/search/vacancy?L_save_area=true&items_on_page=100&area={i}&search_field=name&search_field=company_name&search_field=description&text=&enable_snippets=false\"\n",
    "    response = sess.get(url)\n",
    "    page = bs(response.text, 'html.parser')\n",
    "    find_result = page.find('h1', class_=\"bloko-header-section-3\")\n",
    "    try:\n",
    "        num_of_vacancy = find_result.text[8:-9]\n",
    "        num_of_vacancy = re.sub(r'\\D', '', num_of_vacancy)\n",
    "        if num_of_vacancy:\n",
    "            if int(num_of_vacancy) > 2000:\n",
    "                location_codes.append(i)\n",
    "                print(num_of_vacancy)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "\n",
    "for i in location_codes:\n",
    "    \n",
    "    try:\n",
    "        url = f\"https://chelyabinsk.hh.ru/search/vacancy?L_save_area=true&items_on_page=100&area={i}&search_field=name&search_field=company_name&search_field=description&text=&enable_snippets=false\"\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        urls = get_urls(html, 3900)\n",
    "        all_urls.append(urls)\n",
    "    except:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls_1d = []\n",
    "\n",
    "for i in all_urls:\n",
    "    for j in i:\n",
    "        all_urls_1d.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = list(set(all_urls_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_series = pd.Series(all_urls)\n",
    "urls_series.to_csv('data/hh_vacancies_urls.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/hh_vacancies_urls.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    all_urls = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'id':[],\n",
    "    'title':[],\n",
    "    'description':[],\n",
    "    'salary':[],\n",
    "    'currency':[],\n",
    "    'compensation_type':[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, url in enumerate(all_urls_1d):\n",
    "    \n",
    "    response = sess.get(url)\n",
    "    page = bs(response.text, 'html.parser')\n",
    "    id = url[-8:]\n",
    "    dirty_description = page.find('div', class_=\"g-user-content\")\n",
    "    description = re.sub(r'(\\<(/?[^>]+)>)', '', str(dirty_description))\n",
    "    dirty_title = page.find('h1', class_=\"bloko-header-section-1\")\n",
    "    title = re.sub(r'(\\<(/?[^>]+)>)', '', str(dirty_title))\n",
    "    dirty_salary = page.find('span', class_=\"bloko-header-section-2 bloko-header-section-2_lite\")\n",
    "    salary = re.sub(r'(\\<(/?[^>]+)>)', '', str(dirty_salary))\n",
    "    df.loc[n, 'id'] = id\n",
    "    df.loc[n, 'title'] = title\n",
    "    df.loc[n, 'description'] = description\n",
    "    df.loc[n, 'salary'] = salary\n",
    "    \n",
    "    if n % 2000 == 0:\n",
    "        df.to_csv(f'data\\my_data_hh_{n}.csv', index=False)\n",
    "    \n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
